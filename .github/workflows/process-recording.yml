name: Process Recording

on:
  workflow_dispatch:
    inputs:
      recording_id:
        description: 'Recording ID to process'
        required: true
        type: string
      render_api_url:
        description: 'Render API URL for status updates'
        required: true
        type: string
      render_api_token:
        description: 'Render API token (optional)'
        required: false
        type: string

jobs:
  process:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install AWS CLI
        run: |
          curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
          unzip awscliv2.zip
          sudo ./aws/install

      - name: Install FFmpeg
        run: |
          sudo apt-get update
          sudo apt-get install -y ffmpeg

      - name: Configure AWS CLI for R2
        env:
          R2_ACCOUNT_ID: ${{ secrets.R2_ACCOUNT_ID }}
          R2_ACCESS_KEY_ID: ${{ secrets.R2_ACCESS_KEY_ID }}
          R2_SECRET_ACCESS_KEY: ${{ secrets.R2_SECRET_ACCESS_KEY }}
        run: |
          aws configure set aws_access_key_id $R2_ACCESS_KEY_ID
          aws configure set aws_secret_access_key $R2_SECRET_ACCESS_KEY
          aws configure set region auto

      - name: Download chunks from R2
        env:
          R2_ACCOUNT_ID: ${{ secrets.R2_ACCOUNT_ID }}
          R2_BUCKET_NAME: ${{ secrets.R2_BUCKET_NAME }}
          RECORDING_ID: ${{ inputs.recording_id }}
        run: |
          mkdir -p chunks
          # List all chunks for this recording
          aws s3api list-objects-v2 \
            --endpoint-url https://${R2_ACCOUNT_ID}.r2.cloudflarestorage.com \
            --bucket ${R2_BUCKET_NAME} \
            --prefix "${RECORDING_ID}_chunk_" \
            --query 'Contents[].Key' \
            --output text > chunk_list.txt
          
          # Download each chunk
          while IFS= read -r chunk_key; do
            if [ ! -z "$chunk_key" ]; then
              aws s3 cp \
                --endpoint-url https://${R2_ACCOUNT_ID}.r2.cloudflarestorage.com \
                "s3://${R2_BUCKET_NAME}/${chunk_key}" \
                "chunks/${chunk_key}"
            fi
          done < chunk_list.txt
          
          # Sort chunks by number
          ls -1 chunks/${RECORDING_ID}_chunk_*.webm | sort -V > sorted_chunks.txt

      - name: Merge chunks with FFmpeg
        env:
          RECORDING_ID: ${{ inputs.recording_id }}
        run: |
          if [ ! -s sorted_chunks.txt ]; then
            echo "⚠️ No chunks to merge"
            exit 1
          fi
          
          # Create concat file for FFmpeg
          while IFS= read -r chunk_file; do
            if [ -f "$chunk_file" ]; then
              echo "file '$(pwd)/${chunk_file}'" >> concat_list.txt
            fi
          done < sorted_chunks.txt
          
          if [ ! -s concat_list.txt ]; then
            echo "⚠️ No valid chunks to merge"
            exit 1
          fi
          
          # Merge all chunks into one file
          ffmpeg -f concat -safe 0 -i concat_list.txt -c copy "final_${RECORDING_ID}.webm" || {
            echo "⚠️ FFmpeg merge failed, trying with re-encoding"
            ffmpeg -f concat -safe 0 -i concat_list.txt -c:v libvpx-vp9 -c:a libopus "final_${RECORDING_ID}.webm"
          }
          
          if [ -f "final_${RECORDING_ID}.webm" ]; then
            echo "✅ Merged file size: $(du -h final_${RECORDING_ID}.webm | cut -f1)"
          else
            echo "⚠️ Failed to create merged file"
            exit 1
          fi

      - name: Upload final file to R2
        env:
          R2_ACCOUNT_ID: ${{ secrets.R2_ACCOUNT_ID }}
          R2_BUCKET_NAME: ${{ secrets.R2_BUCKET_NAME }}
          RECORDING_ID: ${{ inputs.recording_id }}
        run: |
          aws s3 cp \
            --endpoint-url https://${R2_ACCOUNT_ID}.r2.cloudflarestorage.com \
            "final_${RECORDING_ID}.webm" \
            "s3://${R2_BUCKET_NAME}/${RECORDING_ID}_final.webm"
          
          echo "✅ Uploaded final file: ${RECORDING_ID}_final.webm"

      - name: Update recording status to ready
        env:
          RENDER_API_URL: ${{ inputs.render_api_url }}
          RENDER_API_TOKEN: ${{ inputs.render_api_token }}
          RECORDING_ID: ${{ inputs.recording_id }}
        run: |
          curl -X PATCH "${RENDER_API_URL}/api/recordings/${RECORDING_ID}" \
            -H "Content-Type: application/json" \
            -H "Authorization: Bearer ${RENDER_API_TOKEN}" \
            -d '{
              "status": "ready",
              "final_file_path": "'"${RECORDING_ID}"'_final.webm"
            }' || echo "⚠️ Failed to update status (non-critical)"

      - name: Cleanup
        if: always()
        run: |
          rm -rf chunks
          rm -f *.webm *.txt

